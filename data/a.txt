Hadoop是什么？先问一下百度吧：

【百度百科】一个分布式系统基础架构，由Apache基金会所开发。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高传输率（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。

Hadoop主要用于一些分布式计算。在这个大数据年代，那这个的确是一个很不错的工具。所以很有必要来学一学。

如何开展这个学习呢，不管怎样，学习一样新东西，我喜欢这样的顺序：先依葫芦画瓢，一步一步行将其运行起来，再来分析一些应用场景及运行的情况，然后深入看一下其高级应用， 最后由于这个是一个开源产品，正好来借此机会来读一读大牛们的代码，学学其精华。

好了，开始行动：